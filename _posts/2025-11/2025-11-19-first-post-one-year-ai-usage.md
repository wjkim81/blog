---
layout: post
title: "What I Learned After Using AI Every Day for a Year"
date: 2025-11-19
published: true
categories: [AI]
tags: [AI, RAG, Research, Productivity]
permalink: /learning-from-one-year-ai-usage/
---

*One Year of Heavy AI Usage (ChatGPT and Claude prompt) — What I Really Learned*

Over the past year, I used AI tools more intensely than almost anyone around me.
Not casually, not for a few prompts a day — but as a core part of my research, writing, system design, and even psychological analysis.

This wasn’t “playing with ChatGPT.”
This was integrating AI into **every layer** of my workflow, every day, for twelve months.

And the result is simple:

> **AI is not magic — but if you learn how to manage it structurally, it becomes one of the most powerful cognitive tools humans have ever had.**

Here’s what I learned.

---

## **1. Prompting is not the real secret — system design is**

Online, people endlessly repeat things like:

* “Be clear in your prompt.”
* “Add examples.”
* “Tell Claude not to hallucinate.”

These tips are fine for beginners, but they solve only **1%** of the real problem.

The real power of AI comes not from “better prompting” but from:

* structured documentation
* clean project files
* clear file hierarchies
* retrieval design
* consistent reasoning logs
* stable context
* multi-step refinement
* domain-specific knowledge
* version control of ideas

AI becomes intelligent **only inside a system that is well-organized**.

Without structure?
The model behaves randomly.
With structure?
The model becomes a superhuman collaborator.

This took me a year to understand fully.

---

## **2. RAG is not a tool — it’s a way of thinking**

People talk about RAG like it’s a simple feature:

> “Upload files and AI magically understands.”

Reality is different.

I discovered RAG **before** I even knew the word.
Every day, I manually attached summaries, rebuilt context, and referenced previous files.
Eventually I realized:

> “Ah… I’m basically doing RAG by hand.”

Real RAG is not about vector databases.
It’s about **knowledge architecture**:

* How do you chunk information?
* What metadata matters?
* What file structure reveals meaning?
* Which documents should be retrieved for which question?
* How do you maintain project memory across months?

This is what almost nobody online understands.
RAG is not coding — it is **designing how your mind and AI connect.**

---

## **3. Heavy AI usage makes you think like a system architect**

One year of intense usage changed my cognition.

I no longer see AI as:

* a chatbot
* a writing tool
* a code generator

Instead, I treat it like:

* a junior engineer
* a research assistant
* a documentation machine
* a reasoning partner
* a multi-disciplinary expert with no ego
* a logic-checking adversary

The key insight:

> **Your structure determines AI’s quality.
> Not the model.
> Not the prompt.
> Your system.**

I now design:

* Markdown knowledge bases
* project ontologies
* RAG-ready datasets
* reasoning logs
* experiment files
* model comparison workflows

This is how AI becomes predictable and stable.

---

## **4. AI makes solo founders dramatically more capable**

One founder today can build:

* backend
* frontend
* RAG pipeline
* data system
* vector search
* UX mockups
* documentation
* prototypes
* research reports

I built my own RAG system + backend in a few days.
Frontend will take a few more days.
One or two years ago, this would have required a small team.

AI didn’t replace developers.
AI multiplied the ability of a **single person** who thinks in systems.

This is the new reality.

---

## **5. Most people don’t know how to use AI — and that’s why disasters happen**

I see many online posts like:

* “Claude 4.5 prompt trick! Quality is 10x better!”
* “RAG in 5 minutes — just upload files!”
* “AI auto-coding deleted my production database!”
* “I was charged $1000 because the agent ran forever!”

These happen because people:

* overtrust AI
* lack system thinking
* don’t understand retrieval
* treat agents as magic
* don’t supervise tasks
* don’t design boundaries
* don’t understand cost structure
* don’t understand architecture

The problem is not AI.
The problem is **using AI without thinking.**

I saw the same pattern when I worked at IBM:
people repeated buzzwords without actually understanding the systems behind them.

Today, that problem is bigger.

---

## **6. True AI expertise comes from long-term, structured use—not hype**

After one year of heavy usage, I finally understand:

* Why some people get mediocre results
* Why others get world-class outcomes
* Why AI feels “inconsistent” for some
* Why AI becomes stable when structured
* Why system architecture matters more than prompts
* Why RAG should be designed from day one
* Why agentic AI is unnecessary until you truly need it
* Why AI is raising the ceiling of individual capability
* Why startup founders can now build so much alone

And most importantly:

> **AI amplifies the quality of your system.
> If you give it chaos, it amplifies chaos.
> If you give it structure, it amplifies intelligence.**

This is the core truth almost nobody talks about.

---

## **7. This year changed how I work, think, and build**

I don’t care much about hype anymore.
Not about “which model is stronger”
or “which tool is better.”

Because my system is what makes AI powerful — not the model itself.

Today, I:

* design knowledge structures
* build AI-powered backends
* use RAG as my cognitive memory
* architect systems instead of coding from scratch
* let AI accelerate repetitive tasks
* focus on reasoning, clarity, and design

AI didn’t make me lazy.
AI made me **more systematic**.

---

## **Conclusion**

A year of heavy AI usage didn’t just improve my productivity.
It changed the way I think, build, and understand systems.

The real transformation wasn’t the tools.
It was my **architecture**,
my **thinking**,
my **process**,
and my **ability to structure knowledge in a way AI can understand**.

AI is not a replacement for human thought.
AI is an amplifier for **well-organized thought**.

And that is the biggest lesson of all.

---

# 🇰🇷 **AI prompt (ChatGPT, Claude)를 1년 동안 매일같이 사용하며 내가 진짜로 느낀 것들**

*AI를 1년간 매일 사용하며 깨달은 핵심*

---

지난 1년 동안 AI 도구를 **내가 지금 진행하고 있는 연구, 사람 심리, 그리고 전반적인 IT 기술 및 여러 분야/주제에** 대해서 ChatGPT, Claude를 매우 강도 높게 써보았다.

그러면서 Prompt로 AI를 쓰는 과정에서 느낀 바는 다음과 같다.

> **AI는 마법이 아니다.
> 그러나 ‘제대로’ 구조화해서 사용하면, 내가 가질 수 있는 강력한 인지 확장 장치가 된다.**

개인적으로 내가 생각하는 중요한 포인트는 “프롬프트 잘 쓰는 법”이 아니라는 점.
그래서 AI를 사용함에 있어서 내가 느낀 것들을 정리해 보면 다음과 같다.

---

## **1. 프롬프트가 아니라 ‘시스템’이 AI의 성능을 결정한다**

온라인에서는 많이들 보는 조언의 예시:

* “명확하게 말하세요”
* “예시를 주세요”
* “추측하지 말라고 하세요”
* “새로운 모델이 발표됐는데, 써보니 좋으니 갈아타자”

초심자에게는 도움이 되지만, 내가 느끼는 **AI 사용의 본질은:**

> **‘내가 만든 시스템’이 잘 구조화되어 있을 때 AI 성능이 우월해진다.**

여기서 내가 말하는 시스템이란

* 문서 구조가 명확하고,
* 프로젝트 파일이 체계화되어 있고,
* 각 노트가 어떤 의미를 갖는지 정리되어 있고,
* 이전 대화와 reasoning이 기록되어 있고,
* 도메인 지식이 파일로 구성되어 있으며,
* 논리적 흐름이 일관되게 저장되어 있기 때문

결론적으로 프롬프트 한 줄보다 중요한 건 **데이터/문서 설계 방식**이다.
구조가 탄탄하면 AI가 답을 잘하고, 구조가 엉망이면 AI 성능도 엉망이 된다는 것이다.

---

## **2. ‘시스템적인 사고방식’이 prompt로 하는 RAG 과정이다**

흔히들 RAG를 API통합을 통한 자동 구현이라 생각하기 쉽겠지만, 프로젝트로 AI를 사용해 보면서 느낀 바는 수동적인 RAG도 prompt를 통해 다음과 같이 구현할 수 있다는 것:

* 관련 요약을 붙이고,
* prompt에 어떤 파일을 제공해야 할지 고민하고,
* 파일 구조를 다시 정리하고,
* 섹션별로 맥락을 맞추고,
* 어떤 질문에 어떤 근본 파일을 줘야 할지 판단

> **이런 부분이 사실상 prompt AI의 추론을 도와줄 수 있도록 한 수동 RAG이다.**

어떻게 보면 API통합과 RAG를 AI system에 녹이기 위해서도 다음과 같은 구조가 필요한데:

* 데이터 구조 설계
* chunking 전략
* retrieval policy
* 문서 계층화
* 메타데이터 기준
* 장기 프로젝트 기억 구조

여기서 중요한 것은 “내가 지식을 어떻게 설계하느냐”가 핵심이고, 벡터 DB는 같은 것은 부속품이다.

---

## **3. AI를 보는 관점 자체도 달라졌다**

예전에 내가 생각하는 AI:

* 챗봇
* 글쓰기 보조
* 코드 생성기
* 통역

이였다면, 이제는:

* 내가 활용할 수 있는 ‘주니어 엔지니어’
* 연구 주제에 대해 아이디어를 정교화할 수 있는 ‘리서치 어시스턴트’
* 내가 만든 프로젝트의 ‘인지 프레임 확장기’
* 그리고, 내가 설계한 환경에 따라 품질이 극적으로 달라지는 존재

로 바뀌었다.

그리고 계속 반복하지만 이를 위해서는

> **AI의 성능은 모델이 아니라 ‘내가 만든 시스템의 품질’로 결정된다.**

구조화된 프로젝트는 AI가 실제적으로 나의 문제를 푸는데 도움이 되도록 만들고,
구조화 되지 못한 프로젝트는 AI를 바보로 만든다.

---

## **4. 1인의 시대 — 혼자서 MVP를 만들 수 있다**

예전에는 스타트업을 만들려면:

* 백엔드 개발자
* 프론트엔드 개발자
* 데이터 엔지니어
* 디자이너
* ML 엔지니어

적어도 3~5명은 필요하거나 몇개월의 시간이 필요했지만,
이제는 흔히들 온라인에서 말하듯이 MVP 개발까지는 혼자서 할 수 있다고 본다.

실제로 코드 작성에 있어 AI 도움을 얻어 MVP 수준의 AI system (RAG + backend + frontend)를 며칠 만에 완성했는데, 예전과 비교하면 framework 공부부터 해서 하나하나 코딩까지 하면 **몇 달** 걸렸을 일이다.

물론 바이프 코딩을 하다보면 기술 스택에 대해서 세부적으로 이해는 못하겠지만, 그래도 이제는 한 사람이:

* 기획
* 설계
* 백엔드
* 프론트
* UX 프로토타이핑
* 문서화
* 코드 리뷰
* RAG
* API 통합

어느 정도 필요한 부분에 대해 전부 할 수 있게 된 것!

그래서 느끼는 바는 이제는 **AI가 한 사람의 능력을 팀 단위로 확장시킬 수 있다고 본다.**

코딩을 구현하는데 들이던 시간을 이제는 실제적으로 무엇을 만들고 싶은가, 어떤 문제를 해결하고 싶은가로 옮기면서 실제 보다 중요한 문제에 대해서 생각을 할 수 있게 된 것 같고, 작은 팀에서 실행할 수 있는 것을 구현해 볼 수 있게 되어서 얻는 이점이 크다고 본다.

---

## **5. AI를 제대로 이해하지 못하면 사고가 난다**

온라인 커뮤니티를 보면, 가끔씩 다음과 같은 글들을 본다.

* “RAG 5분이면 된다!”
* “AI 자동 코딩 돌렸더니 140만원 청구됐다”
* “에이전트가 데이터베이스를 삭제했다”
* “AI가 프로젝트 상태를 기억한다더니 아니었다”

이런 글들에서 느껴지는 것은 AI를 씀에 있어서 기술적인 부분에 대한 이해를 못하고, 새로운 기술 개념이 만능이라고 생각하기 때문인 것 같다.

* 아키텍처 없이 RAG를 쓰고,
* 데이터 구조를 설계하지 않고,
* 프롬프트만 바꾸면 해결된다고 믿고,
* 에이전트에게 무지성으로 권한을 주고,
* 검증 없이 코드를 믿고,
* 추론 흐름을 점검하지 않는다.

내가 보는 문제는 AI가 아니라 **사용자의 시스템 부재와 AI의 정확한 기술 이해 부족**에서 원인으로 보인다.

---

## **6. 그래서 깨달은 점: AI를 다루는 진짜 실력은 ‘AI 사용량’이 아니라 ‘AI로 시스템으로 만드는 능력’**

* 모델의 선택보다 구조화가 중요하다.
* 프롬프트보다 문서 계층이 중요하다.
* 기능보다 프로젝트 설계가 중요하다.
* 자동화보다 인간의 사고가 중요하다.
* API 통합보다 retrieval policy가 중요하다.

이러한 시스템 설계를 통하면 **AI는 내가 만든 문서 구조를 증폭시키는 장치**가 될 수 있다는 것.
내 구조가 정확하면 AI도 정확하고,
내 구조가 흐트러지면 AI도 흔들린다.

사실상 프롬프트보다 훨씬 중요한 부분이라고 생각한다.

---

## **7. 이제는 AI를 도구가 아닌 ‘개인적인 작업 환경’으로 만들어서 사용**

계속해서 모델 업데이트가 나와 더 나은 성능을 보여주기는 하지만,
어느 정도 내가 가진 기준의 성능을 패스하면 사실상 어떤 모델 업데이트의 역량에 크게 기댈 필요는 없다고 생각한다.

이유야 위에서 계속 강조하였듯이 AI의 성능을 결정하는 부분이 **내가 구조화 하는 시스템**에 있기 때문.

그리고 이를 위해서 내 문서 구조를 더 선명하게 만들면서 정리해야 하는데,
내가 하는 연구·심리 분석·IT 작업들이 결국 매일 문서 구조 설계로 이어지고, 그 구조화된 문서를 기반으로 AI의 도움을 받아 문제를 풀고 있다.

그러다 보니 개인적으로 AI 환경 자체가 **내 생각을 정리하고, 확장하는 환경**으로 사용이 되어지고 있다.

---

## **마지막으로 — 이 블로그에서 다루고 싶은 이야기**

앞으로 이 블로그에서는:

* 내가 하는 OCT 연구와 딥러닝 개발 과정에서 느낀 **연구자의 생각들**
* 내가 직접 경험하며 쌓은 **AI 실전 노하우**
* RAG, API 통합, 시스템 설계 같은 **실무 기반 IT 인사이트**

공유해보려고 한다.

그리고 첫글로 1년 동안 AI를 사용하며 느낀 점을 첫 글로 남겨본다.
