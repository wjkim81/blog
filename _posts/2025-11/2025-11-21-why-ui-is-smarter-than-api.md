---
layout: post
title: "ChatGPT/Claude prompt is not simple UI interface"
date: 2025-11-21
published: True
categories: [AI]
tags: [AI, Orchestration, RAG, Prompt]
---

# **I Built a RAG System in 5 Days. Here's Why It Failed (And What I Learned)**

## *5ì¼ ë§Œì— RAG ì‹œìŠ¤í…œì„ ì§ì ‘ êµ¬ì¶•í•˜ë©° ê¹¨ë‹¬ì€ ëª¨ë“  ê²ƒ*

### *Why ChatGPT/Claude UI feels dramatically smarter than API calls â€” and why this changed how I think about building AI systems.*

---

When I spent five days building a RAG system.

On day one, I was confident.
By day three, I was confused.
By day five, I was humbled.

I learned more from this failure than reading tutorials.

Here's what nobody tells you about building AI systems...:

> Upload documents â†’ retrieve â†’ feed into LLM â†’ get nice answers.

Iâ€™ve been using ChatGPT Projects and Claude Workspaces intensively for months.
Their reasoning quality, file-aware analysis, and multi-turn consistency feel almost magical.

So I genuinely thought:

> **â€œIf I use their API and build my own RAG system, I should get similar intelligence.â€**

But the moment I built it myself, I hit a shock that every real AI architect eventually experiences:

> **My RAG system felt dumb.
> Shallow.
> Inconsistent.
> Easily confused.
> Nothing like ChatGPT or Claude UI.**

At first I wondered:

* Was my architecture wrong?
* Did I choose bad embeddings?
* Is my chunking wrong?
* Should I tune prompts harder?
* Am I missing some magic instruction?

But after days of testing, observing, and using OpenAI/Anthropic prompts side-by-side, I realized a deeper truth:

> **ChatGPT UI â‰  ChatGPT API.
> Claude UI â‰  Claude API.**

The UI is not â€œjust the LLM.â€
The UI is an **entire orchestration system** with hidden pipelines, memory, summaries, model routing, multi-pass prompts, and intelligent file processing.

The API is simply the **raw engine**.

My RAG was not dumb â€”
I simply built **2%** of what ChatGPT has behind the scenes.

And once I understood *why*, everything clicked.

---

# **Whatâ€™s Actually Happening Behind ChatGPT/Claude UI (The Part I Never Saw)**

Here is what I realized:
When I upload files into ChatGPT Projects or Claude Workspaces, the system runs a **large pipeline** that looks NOTHING like my simple vector DB workflow.

Below is the closest approximation of whatâ€™s actually happening under the hood â€” the stuff nobody sees, but everyone benefits from.

I rewrote this in my own words, based on everything I learned the hard way.

---

![Tutorial RAG vs Real ChatGPT Orchestration](/assets/images/2025-11-21-tutorial_vs_real_rag.png)

## **Step 1 â€” File Upload = Massive Processing Pipeline**

### **1. File type detection**

```
.py     â†’ parsed into AST (functions, classes, imports)
.md     â†’ hierarchical section parser
.yaml   â†’ schema extraction
.pdf    â†’ text + layout segmentation
```

### **2. Intelligent chunking (not naive fixed-size split)**

* Python â†’ chunk by class/function
* Markdown â†’ chunk by logical section
* Configs â†’ chunk by key/field
* Text â†’ chunk by semantic blocks

Not bitmap splitting.
Not character count splitting.
Not token slicing.

Real structure-aware segmentation.

### **3. Metadata extraction**

```
filename
filetype
import graph
function signatures
docstring summary
referenced files
semantic categories
```

### **4. Embedding creation**

* proprietary embedding models
* optimized for code + prose
* multiple vector indexes:

  * semantic
  * structural
  * dependency-based

In other words:

> **Uploading a file is never just â€œembedding text.â€
> Itâ€™s constructing an entire searchable knowledge graph.**

---

## **Step 2 â€” Query Processing (What Actually Happens When I Ask Something)**

### **1. Intent classification**

My question is classified into categories like:

* â€œhigh-level overviewâ€
* â€œbug diagnosisâ€
* â€œsecurity concernâ€
* â€œdependency tracingâ€
* â€œsummarizationâ€
* â€œrewrite/refactorâ€

Each intent triggers **different retrieval strategies**.

### **2. Multi-strategy retrieval**

Not just embedding search.

They do:

* semantic retrieval
* keyword fallback
* code graph traversal
* reference resolution
* hybrid reranking

### **3. Reranking & selection**

The system determines:

* which chunks matter
* how deep the explanation should go
* which files must be included
* what order the chunks should appear
* how to balance breadth vs depth

### **4. Context construction**

The UI builds a giant structured prompt containing:

* the selected chunks
* metadata
* file boundaries
* conversation history
* special tags
* internal instructions

This is where my RAG system fails â€”
because mine simply pasted â€œtop_k chunksâ€ in random order.

---

## **Step 3 â€” Hidden Prompt Engineering Layer (The Part I Never See)**

This is where the real magic happens.

### **1. System prompt (huge, invisible)**

I never see it, but ChatGPT feeds itself:

```
"You are analyzing a multi-file codebase."
"Always cite sources."
"Maintain file-level consistency."
"Explain dependencies clearly."
"Never hallucinate unknown functions."
...
(1000+ words total)
```

### **2. Metadata injection**

The UI wraps files like:

```
<file name="main.py">
    ...
</file>
```

### **3. Conversation memory**

Older messages arenâ€™t lost â€” they are:

* compressed
* distilled
* reinserted
* summarized

My API system?
It loses memory instantly unless I manually manage it.

### **4. Final prompt assembly**

The actual prompt going into GPT-4/GPT-o/Gemini/Claude:

* can be **50kâ€“200k tokens**
* extremely structured
* heavily organized
* filled with metadata
* engineered for optimal model behavior

But I only see the **final output**, making everything look â€œsimple.â€

---

## **Step 4 â€” Output Post-Processing**

The UI then:

* inserts citations
* formats code blocks
* detects hallucinations
* applies safety rules
* aligns tone
* ensures quality

And then displays the final answer neatly.

### I only see the top 5% of the entire pipeline.

95% is hidden.

---

# **My Personal Realization: Tutorial RAG Is Just the Doorway**

The more I used my own RAG system, the more I saw the gap:

| ChatGPT/Claude UI      | My RAG                |
| ---------------------- | --------------------- |
| orchestration engine   | simple retrieval      |
| hierarchical chunking  | naive chunking        |
| graph-based reasoning  | semantic-only         |
| memory + summary       | no memory             |
| multi-pass reasoning   | single-pass LLM call  |
| intelligent reranking  | top_k brute force     |
| specialized embeddings | generic embeddings    |
| structured prompt      | sloppy pasted context |

It was humbling.

It forced me to accept:

> **Tutorial RAG is just Chapter 1.
> Real AI system design begins after that.**

The moment you realize this, everything changes.

---

# **So What Should *I* Build Instead?**

This is the conclusion I reached:

### **I shouldn't attempt to copy ChatGPT or Claudeâ€™s internal orchestration.**

That would take:

* 50+ engineers
* years of iteration
* proprietary data
* multimodal embeddings
* deeply integrated systems

Instead, what I need is:

### **My own domain-specialized orchestration system**

designed for **my use case**, **my documents**, **my workflows**, and **my domain knowledge**.

A system where:

* I define chunking logic
* I define memory rules
* I define retrieval routing
* I define context construction
* I define evaluation standards
* I design multi-pass reasoning flows
* I enforce my own consistency rules

Something smaller but smarter.
Something achievable.
Something that grows with my research.

This is the path forward.

---

# **Final Reflection â€” My Breakthrough Understanding**

Building my first RAG system wasnâ€™t just a technical exercise.
It opened my eyes to how **deep** modern AI systems actually are.

I realized:

* ChatGPT Projects and Claude Workspaces feel â€œsmartâ€ because they run dozens of hidden systems.
* API-based RAG feels â€œweakâ€ because it is literally **only one LLM call**.
* Tutorial RAG is not the solution â€” it is the *starting point*.
* The true challenge is building **my own orchestration**, not copying theirs.

And in a strange way, this realization gave me real path â€”
because now I know what the real work is.

Fortunately, I am enjoying this learning!

---

ğŸ“Œ Note  
English translation below was created with AI-assisted translation workflow.

---

# *ChatGPT/Claude í”„ë¡œì íŠ¸ UIëŠ” ë‹¨ìˆœí•œ â€œí”„ë¡¬í”„íŠ¸ ì…ë ¥ì°½â€ì´ ì•„ë‹ˆë‹¤*

---

## **ë‚˜ëŠ” 5ì¼ ë™ì•ˆ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ì—ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ 5ì¼ì´ ë‚´ê°€ ì¤€ ê¹¨ë‹¬ìŒ**

ì²«ì§¸ ë‚ , ìì‹ ê°ì— ì°¸.
ì…‹ì§¸ ë‚ , í˜¼ë€ìŠ¤ëŸ¬ì›€.
ë‹¤ì„¯ì§¸ ë‚ , ê²¸ì†.

íŠœí† ë¦¬ì–¼ë³´ë‹¤ ì‹¤íŒ¨ë§Œ ë³´ì•˜ë‹¤.

ì²˜ìŒì—ëŠ” ë‹¨ìˆœíˆ ì´ë ‡ê²Œ ìƒê°í–ˆë‹¤:

> ë¬¸ì„œ ì—…ë¡œë“œ â†’ ë²¡í„° ê²€ìƒ‰ â†’ LLMì— ì „ë‹¬ â†’ ì¢‹ì€ ë‹µë³€ ìƒì„±.

ê·¸ë™ì•ˆ ChatGPT, Claude Projectsê°€ ì•ˆì •ì ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆë„ë¡ í™œìš©í•˜ë©´ì„œ
ê·¸ë“¤ì˜ **ì¶”ë¡  ëŠ¥ë ¥**, **íŒŒì¼ ê°ì§€ ëŠ¥ë ¥**, **ë¬¸ë§¥ ìœ ì§€ë ¥**, **ë‹¤ì¤‘ í„´ ì¼ê´€ì„±**ì€ ê±°ì˜ ì‹ ì„¸ê³„ì²˜ëŸ¼ ëŠê»´ì¡Œë‹¤.

ê·¸ë˜ì„œ í•œì¸µ ë” ë‚˜ì•„ê°€ì„œ

> **â€œAPIë¡œ ë‚˜ë§Œì˜ RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ë©´, ChatGPT/Claude UIì™€ í›¨ì”¬ ë„ì›€ ë˜ëŠ” AI toolì„ ë§Œë“¤ ìˆ˜ ìˆê² ì§€.â€**

í•˜ì§€ë§Œ ì§ì ‘ ë§Œë“¤ì–´ë³¸ ìˆœê°„, ëª¨ë“  AI ì—”ì§€ë‹ˆì–´ê°€ í•œ ë²ˆì€ ê²ªëŠ” ì¶©ê²©ì„ ë§ë‹¥ëœ¨ë ¸ë‹¤.

> **ë‚´ RAG ì‹œìŠ¤í…œì€ ì™„ì „ ë°”ë³´ë¼ëŠ” ê²ƒ.
> ChatGPT, Claude prompotë¡œ ì–»ì–´ë‚´ëŠ” ë‹µë³€ê³¼ëŠ” ë¹„êµë„ ë˜ì§€ ì•Šì•˜ë‹¤.**

ê·¸ë˜ì„œ ìƒê°í•œê²Œ

* êµ¬ì¡°ê°€ ì˜ëª»ëœ ê±´ê°€?
* ì„ë² ë”©ì´ ë¬¸ì œì¸ê°€?
* ì²­í‚¹ì´ ì˜ëª»ëë‚˜?
* ìˆ¨ê²¨ì§„ ë¹„ë°€ ì„¤ì •ì´ ìˆëŠ” ê±´ê°€?
* ë‚´ê°€ RAGë¥¼ ì™„ì „íˆ ì˜ëª»í•˜ê³  ìˆë‚˜?

í•˜ì§€ë§Œ API ê¸°ë°˜ RAGì™€ ChatGPT UIë¥¼ ìì„¸íˆ ë¹„êµí•˜ë©´ì„œ ì•Œì•„ë‚¸ ê±´:

> **ChatGPT UI â‰  ChatGPT API
> Claude UI â‰  Claude API**

UIëŠ” ë‹¨ìˆœí•œ LLM ì…ë ¥ì°½ì´ ì•„ë‹ˆë¼ëŠ” ê²ƒ.
UIì—ì„œ ë³´ì´ëŠ” prompt ë’¤ë¡œ **íŒŒì¼ ì²˜ë¦¬, ë©”ëª¨ë¦¬, ìš”ì•½, ëª¨ë¸ ë¼ìš°íŒ…, ë©€í‹° íŒ¨ìŠ¤ í”„ë¡¬í”„íŠ¸, êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹ ë“±**ìœ¼ë¡œ ì´ë£¨ì–´ì§„ **ì™„ì „í•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ**ì´ë‹¤.

ê·¸ë¦¬ê³ , APIëŠ” ë‹¨ìˆœí•œ **ì—”ì§„ ê·¸ ìì²´**ì¼ ë¿.

ê²°êµ­ RAG ì‹œìŠ¤í…œì—ì„œ ë‚´ê°€ ë§Œë“  ê²ƒì€ **ChatGPTì˜ 2% ì •ë„**ì— ë¶ˆê³¼í–ˆë˜ ê²ƒì´ë‹¤.

ê·¸ë¦¬ê³  ì´ êµ¬ì¡°ë¥¼ ì œëŒ€ë¡œ ì´í•´í•˜ì ëª¨ë“  ê²ƒì´ ëª…í™•í•´ì¡Œë‹¤.

---

# **ChatGPT/Claude UI ë’¤ì—ì„œ ì‹¤ì œë¡œ ëŒì•„ê°€ëŠ” ê²ƒë“¤**

ì‚¬ì‹¤ ê·¸ë™ì•ˆ ì‚¬ìš©í•˜ë©´ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•  ë•Œ ChatGPTë‚˜ Claudeê°€ ì–´ë–¤ íŒŒì´í”„ë¼ì¸ì„ ëŒë¦¬ëŠ”ì§€ ì „í˜€ ëª°ëë‹¤.

ë‹¨ìˆœí•˜ê²Œ ë§Œë“  ë§Œë“  ë²¡í„° ê²€ìƒ‰ í˜•íƒœì˜ RAGëŠ” ê·¸ ì‹œìŠ¤í…œê³¼ëŠ” **ë¹„êµë„ ì•ˆ ë˜ëŠ” ë‹¨ìˆœí•œ í˜•íƒœ**ì¸ë°, ëœ¯ì–´ë³´ë©´ ì‹¤ì œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **ê±°ëŒ€í•œ íŒŒì´í”„ë¼ì¸**ì´ ëŒì•„ê°€ê³  ìˆë‹¤.

---

![Tutorial RAG vs Real ChatGPT Orchestration](/assets/images/2025-11-21-tutorial_vs_real_rag.png)

## **1ë‹¨ê³„ â€” íŒŒì¼ ì—…ë¡œë“œ = ëŒ€ê·œëª¨ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸**

### **â‘  íŒŒì¼ íƒ€ì… ë¶„ì„**

```
.py     â†’ AST ë¶„ì„(í•¨ìˆ˜, í´ë˜ìŠ¤, import êµ¬ì¡°)
.md     â†’ ê³„ì¸µì  ì„¹ì…˜ íŒŒì„œ
.yaml   â†’ ìŠ¤í‚¤ë§ˆ ë¶„ì„
.pdf    â†’ í…ìŠ¤íŠ¸ + ë ˆì´ì•„ì›ƒ ì„¸ê·¸ë©˜í…Œì´ì…˜
```

### **â‘¡ ì§€ëŠ¥í˜• ì²­í‚¹ (ë‹¨ìˆœ ë¶„í• ì´ ì•„ë‹˜)**

* Python â†’ í•¨ìˆ˜/í´ë˜ìŠ¤ ë‹¨ìœ„ë¡œ
* Markdown â†’ ì„¹ì…˜ ë‹¨ìœ„ë¡œ
* YAML â†’ í•„ë“œ ë‹¨ìœ„ë¡œ
* í…ìŠ¤íŠ¸ â†’ ì˜ë¯¸ ë‹¨ë½ ê¸°ì¤€ìœ¼ë¡œ

ë¬¸ì ìˆ˜ ê¸°ì¤€ ë¶„í• ì´ ì•„ë‹ˆë‹¤.
í† í° ìˆ˜ ê¸°ì¤€ë„ ì•„ë‹ˆë‹¤.
**ë¬¸ì„œ êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹ì´ë‹¤.**

### **â‘¢ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ**

```
íŒŒì¼ëª…
íƒ€ì…
ì˜ì¡´ì„± ê·¸ë˜í”„(import graph)
í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜
docstring ìš”ì•½
ì°¸ì¡°ëœ íŒŒì¼
ì£¼ì œ ì¹´í…Œê³ ë¦¬
```

### **â‘£ ì„ë² ë”© ìƒì„±**

* ì „ìš© ì„ë² ë”© ëª¨ë¸ (í…ìŠ¤íŠ¸ + ì½”ë“œ í†µí•©)
* ì˜ë¯¸/êµ¬ì¡°/ì˜ì¡´ì„± ê¸°ë°˜ ë‹¤ì¤‘ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±

ì¦‰, íŒŒì¼ ì—…ë¡œë“œëŠ” ë‹¨ìˆœ â€œí…ìŠ¤íŠ¸ ì„ë² ë”©â€ì´ ì•„ë‹ˆë‹¤.

> **ì—…ë¡œë“œ = ë¯¸ë‹ˆ ì§€ì‹ ê·¸ë˜í”„ êµ¬ì¶•ì´ë‹¤.**

---

## **2ë‹¨ê³„ â€” ì§ˆë¬¸ì„ ì…ë ¥í•  ë•Œ ì‹¤ì œë¡œ ì¼ì–´ë‚˜ëŠ” ì¼**

### **â‘  ì˜ë„ ë¶„ë¥˜**

ì˜ˆ: "ì¸ì¦ êµ¬ì¡° ì„¤ëª…" vs â€œë³´ì•ˆ ë¬¸ì œ ì°¾ì•„ì¤˜â€ëŠ” ë‹¤ë¥¸ retrieval ì „ëµì´ í•„ìš”í•˜ë‹¤.

### **â‘¡ ë‹¤ì¤‘ ë°©ì‹ ê²€ìƒ‰**

ë‹¤ìŒì´ ëª¨ë‘ ì‹¤í–‰ë¨:

* ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
* í‚¤ì›Œë“œ ê¸°ë°˜ ë³´ì¡° ê²€ìƒ‰
* ì½”ë“œ ê·¸ë˜í”„ íƒìƒ‰
* ì°¸ì¡° íŒŒì¼ ì¶”ì 
* í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹

### **â‘¢ ì¬ë­í‚¹**

* ì–´ë–¤ ì²­í¬ê°€ ì¤‘ìš”í•œê°€?
* ì–´ëŠ ê¹Šì´ë¡œ ì„¤ëª…í•´ì•¼ í•˜ëŠ”ê°€?
* íŒŒì¼ ìˆœì„œë¥¼ ì–´ë–»ê²Œ ë°°ì¹˜í• ê¹Œ?
* ëŒ€í™” íë¦„ê³¼ ì–´ë–»ê²Œ ì—°ê²°í• ê¹Œ?

### **â‘£ ë¬¸ë§¥ êµ¬ì„±**

ChatGPT UIëŠ” ê±°ëŒ€í•œ êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“ ë‹¤.

* ì„ íƒëœ ì²­í¬
* ë©”íƒ€ë°ì´í„°
* íŒŒì¼ ê²½ê³„
* ëŒ€í™” ê¸°ë¡ ìš”ì•½
* ë‚´ë¶€ ëª…ë ¹ì–´

ë‚´ê°€ ë§Œë“  RAGëŠ” ê·¸ëƒ¥ â€œtop_k ì²­í¬ ë‚˜ì—´â€ì´ì—ˆë‹¤.

---

## **3ë‹¨ê³„ â€” ìˆ¨ê²¨ì§„ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ë ˆì´ì–´**

### **â‘  ë‚´ë¶€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë§¤ìš° ê¹€)**

ë³´ì´ì§€ ì•ŠëŠ” ê³³ì—ì„œ ChatGPTëŠ” ìŠ¤ìŠ¤ë¡œì—ê²Œ ë‹¤ìŒì„ ë§í•œë‹¤:

```
â€œì§€ê¸ˆì€ ë‹¤ì¤‘ íŒŒì¼ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ëª¨ë“œë‹¤.â€
â€œí•­ìƒ íŒŒì¼ëª…ìœ¼ë¡œ ì¸ìš©í•˜ë¼.â€
â€œì¢…ì†ì„± ì„¤ëª…ì„ ëª…í™•íˆ í•˜ë¼.â€
...
(ìˆ˜ì²œ ë‹¨ì–´)
```

### **â‘¡ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì£¼ì…**

```
<file name="main.py">
    ...
</file>
```

### **â‘¢ ëŒ€í™” ìš”ì•½ + ë©”ëª¨ë¦¬ ê´€ë¦¬**

* ì´ì „ ëŒ€í™” ìš”ì•½
* ì¤‘ìš”í•œ ì‚¬ì‹¤ ì¶”ì¶œ
* ì••ì¶• í›„ ì¬ì‚½ì…

ë‚´ API ì‹œìŠ¤í…œì—ëŠ” ì—†ë‹¤.

### **â‘£ ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°ë¦½**

* 5ë§Œ~20ë§Œ í† í°
* êµ¬ì¡°í™”ëœ giant prompt
* LLMì´ ê°€ì¥ ì˜ ì´í•´í•˜ë„ë¡ ìµœì  êµ¬ì„±

ìš°ë¦¬ëŠ” **ë³´ì—¬ì§€ëŠ” ì¶œë ¥ë§Œ** ë³¸ë‹¤.

---

## **4ë‹¨ê³„ â€” ì¶œë ¥ í›„ì²˜ë¦¬**

UIëŠ” ìë™ìœ¼ë¡œ:

* ì˜¤íƒ€/í™˜ê° ê²€ì‚¬
* ì½”ë“œ í¬ë§·íŒ…
* ì¸ìš© ì •ë¦¬
* ìŠ¤íƒ€ì¼ ì¡°ì •

ê·¸ë¦¬ê³  ê¹”ë”í•œ ë‹µë³€ì´ ë°˜í™˜ëœë‹¤.

ìš°ë¦¬ê°€ ë³´ëŠ” ê±´ ë‹¨ 5%ë‹¤.
95%ëŠ” ë³´ì´ì§€ ì•ŠëŠ”ë‹¤.

---

# **ë‚´ê°€ ê¹¨ë‹¬ì€ í•µì‹¬: íŠœí† ë¦¬ì–¼ RAGëŠ” â€˜ì…êµ¬â€™ì¼ ë¿ì´ë‹¤**

| ChatGPT/Claude UI | ë‚´ê°€ ë§Œë“  RAG   |
| ----------------- | ----------- |
| ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì—”ì§„        | ë‹¨ìˆœ í˜¸ì¶œ       |
| êµ¬ì¡° ê¸°ë°˜ ì²­í‚¹          | naive ë¶„í•     |
| ê·¸ë˜í”„ ê¸°ë°˜ ì¶”ë¡          | ë‹¨ìˆœ semantic |
| ë©€í‹° íŒ¨ìŠ¤ ì¶”ë¡           | ë‹¨ì¼ í˜¸ì¶œ       |
| ë™ì  ë©”ëª¨ë¦¬            | ì—†ìŒ          |
| ì§€ëŠ¥í˜• ì¬ë­í‚¹           | top_k brute |
| ê³ ê¸‰ ì„ë² ë”©            | ì¼ë°˜ ì„ë² ë”©      |
| êµ¬ì¡°í™”ëœ ê±°ëŒ€ í”„ë¡¬í”„íŠ¸      | ê·¸ëƒ¥ ë¶™ì—¬ë„£ê¸°     |

ê·¸ë˜ì„œ ì´ê±¸ ë³´ë©´ ì†”ì§íˆ ì¸ì •í•  ìˆ˜ ë°–ì— ì—†ë‹¤.

> **íŠœí† ë¦¬ì–¼ RAGëŠ” ì±•í„° 1ì´ë‹¤.
> ë³¸ê²©ì ì¸ AI ì‹œìŠ¤í…œ ì„¤ê³„ëŠ” ê·¸ ì´í›„ì—ì„œ ì‹œì‘í•œë‹¤.**

---

# **ê·¸ë˜ì„œ ë¬´ì—‡ì„ ë§Œë“¤ì–´ì•¼ í• ê¹Œ?**

ë‚˜ì˜ ê²°ë¡ ì€:

### **ChatGPT/Claudeì˜ ë‚´ë¶€ ì‹œìŠ¤í…œì„ ê·¸ëŒ€ë¡œ ë³µì œí•˜ë ¤ í•´ì„œëŠ” ì•ˆ ëœë‹¤.**

ëŒ€ì¶© ë³´ì•„ë„ ChatGPT/Claudeì˜ ë‚´ë¶€ ì‹œìŠ¤í…œì—ì„œëŠ”:

* ìˆ˜ì‹­ ëª…ì˜ ì—”ì§€ë‹ˆì–´
* ìˆ˜ë…„ì˜ ë°˜ë³µ
* ìˆ˜ì‹­ì–µ ê±´ì˜ ë°ì´í„°
* ìì²´ ëª¨ë¸/ì„ë² ë”©/ë©”ëª¨ë¦¬

ì´ í•„ìš”í•œ ì¼ì„ í•´ë‚¸ ê²ƒì´ë‹¤.

ê·¸ë˜ì„œ ë‚˜ ê°™ì€ ì†Œí˜•í™”ëœ í”„ë¡œì íŠ¸ì—ì„œë¼ë©´:

### **ë‚˜ë§Œì˜ ë„ë©”ì¸ íŠ¹í™” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œìŠ¤í…œ**

* ë‚´ê°€ ë‹¤ë£¨ëŠ” ë¬¸ì„œ
* ë‚´ê°€ ë§Œë“  ë¦¬ì„œì¹˜
* ë‚´ê°€ ì›í•˜ëŠ” ì¶”ë¡  ë°©ì‹
* ë‚˜ì˜ í”„ë¡œì íŠ¸ ì›Œí¬í”Œë¡œìš°

ì—¬ê¸°ì— ìµœì í™”ëœ ì‹œìŠ¤í…œì„ ì¶”êµ¬í•´ì•¼ ëœë‹¤ëŠ” ê²ƒ.

ì¦‰, ë‚´ê°€ ë§Œë“  ë¬¸ì„œ êµ¬ì¡° ë° ì‹œìŠ¤í…œ ë¡œì§ì—ë§Œ ë§ëŠ”:

ë‚´ê°€ ì •í•œ ì²­í‚¹ ê·œì¹™
ë‚´ê°€ ì •í•œ ë©”ëª¨ë¦¬ ê·œì¹™
ë‚´ê°€ ì •í•œ retrieval flow
ë‚´ê°€ ì •í•œ context ì¬êµ¬ì„±
ë‚´ê°€ ì •í•œ multi-pass reasoning

ë“±ë“±ì„ ì§ì ‘ ì„¤ê³„í•˜ëŠ” ê²ƒì´ë‹¤.

ê·œëª¨ëŠ” ì‘ì§€ë§Œ, ë˜‘ë˜‘í•œ ì‹œìŠ¤í…œ.
ë³µì¡í•˜ì§€ ì•Šì§€ë§Œ, ì‹¤ìš©ì ì¸ ì‹œìŠ¤í…œ.
íŠœí† ë¦¬ì–¼ì„ ë„˜ì–´, *ë‚˜ë§Œì˜ ì‹œìŠ¤í…œ.*

ê·¸ë˜ì„œ ì´ ì¡°ê¸ˆí•œ AI ì‹œìŠ¤í…œì—ì„œëŠ” ì›í•˜ëŠ” ë‹µë³€ì„ ì œëŒ€ë¡œ ë‹µë³€í•´ë‚˜ê°€ëŠ” ê²ƒ.
ê·¸ê²ƒì´ ì˜¬ë°”ë¥¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì˜ ë°©í–¥ì´ ì•„ë‹ê¹Œ ìƒê°í•œë‹¤.

---

# **ë§ˆì§€ë§‰ ê¹¨ë‹¬ìŒ â€” ë“œë””ì–´ ì‹¤ì²´ì— ì ‘ê·¼í•´ ë³´ì•˜ë‹¤.**

RAG ì‹œìŠ¤í…œì„ ë§Œë“¤ë©´ì„œ ë‚˜ëŠ” LLM ëª¨ë¸ ë’¤ë¡œ ì¼ì–´ë‚˜ëŠ” ì¼ì— ëŒ€í•´ì„œ ì²˜ìŒìœ¼ë¡œ ëª¸ì„œ ëŠë¼ê²Œ ëœ ê²ƒ ê°™ë‹¤.

* ChatGPT/Claudeê°€ â€œë˜‘ë˜‘í•´ ë³´ì´ëŠ” ì´ìœ â€ëŠ” ìˆ¨ê²¨ì§„ ì‹œìŠ¤í…œ ë•Œë¬¸ì´ë‹¤.
* API ê¸°ë°˜ RAGëŠ” â€œì—”ì§„ë§Œ ë…¸ì¶œâ€ëœ ìƒíƒœë‹¤.
* íŠœí† ë¦¬ì–¼ RAGëŠ” ì •ë‹µì´ ì•„ë‹ˆë¼ **ì…êµ¬**ë‹¤.
* ì§„ì§œ ì‹œìŠ¤í…œì€ **ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**ì´ë‹¤.
* ê·¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì€ **ê°ìì˜ ë„ë©”ì¸ì— ë§ê²Œ** ì§ì ‘ ì„¤ê³„í•´ì•¼ í•œë‹¤.

ê·¸ë¦¬ê³  ì´ëŸ° ê²½í—˜ ë•Œë¬¸ì— ë°©í–¥ë„ ë³´ì´ê²Œ ëœ ê²ƒ ê°™ë‹¤.

> ë¬´ì—‡ì„ ë” ë°°ì›Œì•¼ í• ì§€ë„ ì•Œê²Œ ë˜ì—ˆê³ , ë‚´ê°€ ë§Œë“¤ê³  ì‹œìŠ¤í…œì— ëŒ€í—Œ ë³´ë‹¤ ì§„ì§€í•œ ìƒê°ì„ í•˜ê²Œ ë˜ì—ˆë‹¤.

ìƒê°ë³´ë‹¤ ì¬ë¯¸ìˆëŠ” ì—¬ì •ì´ë¼ ë‹¤í–‰ì´ë¼ê³  ìƒê°í•œë‹¤.